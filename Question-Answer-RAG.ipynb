{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "PDF-QA Pipeline:\n",
    "Load a PDF, split pages into chunks, embed, retrieve, and generate answers citing page numbers."
   ],
   "id": "ac2857f7d17ee417"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T07:09:54.686445Z",
     "start_time": "2025-06-05T07:09:54.669313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from chromadb.utils.embedding_functions.sentence_transformer_embedding_function import    SentenceTransformerEmbeddingFunction\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "from pymongo.server_selectors import any_server_selector\n",
    "from transformers.models.auto.configuration_auto import model_type_to_module_name\n",
    "\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n"
   ],
   "id": "adef66dda2184357",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load PDF with Pages as metadata",
   "id": "1c6013cac6f338b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T07:09:54.730176Z",
     "start_time": "2025-06-05T07:09:54.719751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_pdf(pdf_path):\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load_and_split()\n",
    "    for i in range(len(pages)):\n",
    "        pages[i].metadata['page_number'] = i+1\n",
    "    return pages"
   ],
   "id": "a2e673ab05cc1c51",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Split into chunks",
   "id": "f4bc1c9e37518c0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T07:09:54.796700Z",
     "start_time": "2025-06-05T07:09:54.778593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_document(documents):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=800,chunk_overlap=200)\n",
    "    return splitter.split_documents(documents)"
   ],
   "id": "cd2ec9422472f32d",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Embedded chunks",
   "id": "40067e5a05484cf4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T07:09:54.844999Z",
     "start_time": "2025-06-05T07:09:54.839778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_vectorestore(chunks):\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "    )\n",
    "    vectorestore = FAISS.from_documents(chunks,embedding_model)\n",
    "    return vectorestore\n"
   ],
   "id": "404ca953353f2d66",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LLM for Groq",
   "id": "8587d3f89b58d018"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T07:09:54.894449Z",
     "start_time": "2025-06-05T07:09:54.888568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_llm():\n",
    "    return ChatGroq(api_key=groq_api_key,model_name = \"llama-3.3-70b-versatile\")"
   ],
   "id": "47b769b581dbdbf0",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Retrival QA chain",
   "id": "75bc199a43cd368b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T07:09:54.959592Z",
     "start_time": "2025-06-05T07:09:54.952072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_qa_chain(vectorestore):\n",
    "    retriever = vectorestore.as_retriever()\n",
    "    llm = get_llm()\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm = llm,\n",
    "        retriever = retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    return qa_chain\n"
   ],
   "id": "1ef9e0f943e2838b",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Asking a question and citing the sources",
   "id": "637244bb8984d84a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T07:09:55.025541Z",
     "start_time": "2025-06-05T07:09:55.016156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def answer_question(qa_chain,query):\n",
    "    result = qa_chain.invoke({\"query\" : query})\n",
    "    answer = result['result']\n",
    "    sources = result['source_documents']\n",
    "\n",
    "    cited_pages = []\n",
    "    for doc in sources:\n",
    "        page_number = doc.metadata.get(\"page_number\",\"N/A\")\n",
    "        if page_number not in cited_pages:\n",
    "            cited_pages.append(page_number)\n",
    "\n",
    "    cited_pages.sort()\n",
    "\n",
    "    # Convert all page numbers to strings\n",
    "    page_numbers_as_text = []\n",
    "    for page in cited_pages:\n",
    "        page_numbers_as_text.append(str(page))\n",
    "\n",
    "    # Join them with commas\n",
    "    joined_pages = \", \".join(page_numbers_as_text)\n",
    "\n",
    "    # Create the citation text\n",
    "    citation_text = \"\\n\\nðŸ“„ **Cited Pages**: \" + joined_pages\n",
    "\n",
    "    return answer+citation_text"
   ],
   "id": "e309f2625b37e1e3",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Main Function",
   "id": "215fbbf955bb46b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T07:10:08.467370Z",
     "start_time": "2025-06-05T07:09:55.057195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"artificial_intelligence.pdf\"\n",
    "    print(\"Loading and processing the PDF\")\n",
    "    docs = load_pdf(pdf_path)\n",
    "    chunks = split_document(docs)\n",
    "    vectorstore = create_vectorestore(chunks)\n",
    "    qa_chain = build_qa_chain(vectorstore)\n",
    "\n",
    "    # Example query\n",
    "    question = \"What are the key points discussed in the document?\"\n",
    "    print(\"\\n Question:\", question)\n",
    "    response = answer_question(qa_chain, question)\n",
    "    print(\"\\n Answer:\\n\", response)"
   ],
   "id": "3c4ea4954b4b4710",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing the PDF\n",
      "\n",
      " Question: What are the key points discussed in the document?\n",
      "\n",
      " Answer:\n",
      " The key points discussed in the document are:\n",
      "\n",
      "1. Introduction to Natural Language Processing (NLP) and its steps.\n",
      "2. The five general steps in NLP are not explicitly listed, but two of them are mentioned: \n",
      "   - Lexical Analysis: identifying and analyzing the structure of words.\n",
      "   - Syntactic Analysis (Parsing): analyzing words in a sentence for grammar and arranging words to show their relationships.\n",
      "3. Various concepts related to NLP, including:\n",
      "   - Morphology: the study of word construction.\n",
      "   - Morpheme: the primitive unit of meaning in a language.\n",
      "   - Syntax: arranging words to make a sentence.\n",
      "   - Semantics: the meaning of words and how to combine them into phrases and sentences.\n",
      "   - Pragmatics: using and understanding sentences in different situations.\n",
      "   - Discourse: how the preceding sentence affects the interpretation of the next sentence.\n",
      "   - World Knowledge: general knowledge about the world.\n",
      "4. Text Realization: mapping sentence plan into sentence structure.\n",
      "5. The difficulties in Natural Language Understanding (NLU), including:\n",
      "   - The rich form and structure of natural language.\n",
      "   - Ambiguity in natural language, including lexical ambiguity.\n",
      "6. A disclaimer and copyright notice from Tutorials Point (I) Pvt. Ltd.\n",
      "\n",
      "ðŸ“„ **Cited Pages**: 1, 39, 40\n"
     ]
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
